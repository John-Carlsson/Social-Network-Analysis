{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1: Network Identification\n",
    "Consider the network N represented in the file net_x, where x is your group number.\n",
    "This network has been generated with one of the network models seen during the course.\n",
    "You have to analyze the network N with the network mining tools (the ones shortlisted in the\n",
    "midterm project) and guess which model has been used for creating it. Your guess has to be\n",
    "supported by an appropriate set of experiments to confirm that networks generated with the\n",
    "proposed model have characteristics similar to N (note that you have to guess also the parameters of\n",
    "the model).\n",
    "During the discussion of the project, you will be asked to motivate your guess. Motivations may be\n",
    "related to both theoretical properties of the models seen during the course (e.g., “I analyzed the\n",
    "provided network and I observed that its node degree distribution follows a power law. Hence, I\n",
    "conclude that it is not possible that the graph has been generated with a model random(n, p).”), and\n",
    "to experimental evidence (e.g., “I generated a lot of random graphs with p = 1/3, and none of them\n",
    "had similar properties as the provided network. Hence I conclude that it is improbable that the graph\n",
    "is random(n, 1/3)”).\n",
    "A bonus point will be assigned to all the components of the groups whose guess is closer to the\n",
    "model (and parameters) used to generate N.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1:\n",
    "import networkx as nx\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import math\n",
    "from scipy.sparse import linalg\n",
    "import random\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of graphs it can be:\n",
    "configurationG(deg)\n",
    "power_law_degree(n,power)\n",
    "preferentialG(n,p)\n",
    "GenWS2DG(n, r, k, q)\n",
    "affiliationG(n, m, q, c, p, s)\n",
    "randomG(n,p)\n",
    "\n",
    "\n",
    "info:\n",
    "Is undirected\n",
    "follows a normal distribution of neighbors with mean 23.3\n",
    "\n",
    "Parameters:\n",
    "Nodes: 20000\n",
    "edges: 227739\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "227739\n",
      "True\n",
      "23.24426676942118\n",
      "1424 0.0021001050052502626\n",
      "10443 0.000200010000500025\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "with open('net_3', 'r') as f:\n",
    "    for s in f.readlines():\n",
    "        G.add_edge(s.split()[0], s.split()[1])\n",
    "\n",
    "\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "# graph is connected\n",
    "print(nx.is_connected(G))\n",
    "\n",
    "# Average degree of neighbors in the graph, tells us that on average a neihgbor of a node has 23.24 connections\n",
    "# which is a very connected graph\n",
    "mean_deg = print(np.mean(list(nx.average_neighbor_degree(G).values())))\n",
    "\n",
    "#print(nx.node_connectivity(g))\n",
    "\n",
    "s = nx.degree_alg.degree_centrality(G)\n",
    "max_k = '0'\n",
    "min_k = '0'\n",
    "for k in s:\n",
    "    if s[k] >= s[max_k]:\n",
    "        max_k = k\n",
    "    if s[k] <= s[min_k]:\n",
    "        min_k = k   \n",
    "print(max_k, s[max_k]) # very low centrality overall, max is 0.0021\n",
    "print(min_k, s[min_k]) # min is 0.00020, which is 10 times lowe than the max\n",
    "\n",
    "#print(nx.diameter(g)) # Should take some time to compute. Value is:\n",
    "a = []\n",
    "for i in G.nodes:\n",
    "    a.append(len(G[i]))\n",
    "\n",
    "std_deg = np.std(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the different kinds of centralities\n",
    "import networkx as nx\n",
    "def centrality(G):\n",
    "    # degree centrality\n",
    "    d_cen = nx.degree_centrality(G) # takes 5 seconds\n",
    "    print('degree done')\n",
    "    # closeness centrality\n",
    "    c_cen = nx.closeness_centrality(G) # takes 12 minutes\n",
    "    print('closeness done')\n",
    "    # betweenness centrality\n",
    "    b_cen = nx.betweenness_centrality(G) # takes forever 50\n",
    "    print('betweenness done')\n",
    "    # eulerian centrality\n",
    "    #e_cen = nx.eigenvector_centrality(G)\n",
    "    #print('eulerian done')\n",
    "    # return the different centralities\n",
    "    return [[min(d_cen),max(d_cen)], [min(c_cen),max(c_cen)], [min(b_cen),max(b_cen)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.148997843269395\n",
      "22.7739\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['nodes'] = G.nodes\n",
    "df['number of neighbors'] = [len(G[i]) for i in df['nodes']]\n",
    "#df['centrality'] = [nx.centrality.closeness.closeness_centrality(g,i) for i in df['nodes']]\n",
    "print(np.std(df['number of neighbors']))\n",
    "print(np.mean(df['number of neighbors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "degree done\n",
      "closeness done\n"
     ]
    }
   ],
   "source": [
    "dfG = pd.DataFrame(centrality(G), columns=['Degree', 'Closeness', 'Betweenness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "hist_facit = sns.histplot(df['number of neighbors'])\n",
    "sns.PairGrid.savefig(hist_facit,'./figures/histo_facit.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mean_deg = 23\n",
    "num_nodes = 20000\n",
    "std_dev = 5\n",
    "degrees = np.round(np.random.normal(mean_deg, std_dev, num_nodes)).astype(int)\n",
    "\n",
    "if sum(degrees) % 2 != 0:\n",
    "    degrees[0]-=1\n",
    "g = nx.configuration_model(degrees)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfg = pd.DataFrame(centrality(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nx.degree_alg.degree_centrality(G)\n",
    "max_k = '0'\n",
    "min_k = '0'\n",
    "for k in s:\n",
    "    if s[k] >= s[max_k]:\n",
    "        max_k = k\n",
    "    if s[k] <= s[min_k]:\n",
    "        min_k = k   \n",
    "print('Centrality for net_3')\n",
    "print(max_k, s[max_k]) # very low centrality overall, max is 0.0021\n",
    "print(min_k, s[min_k]) # min is 0.00020, which is 10 times lowe than the\n",
    "s = nx.degree_alg.degree_centrality(g)\n",
    "max_k = 0\n",
    "min_k = 0\n",
    "for k in s:\n",
    "\n",
    "    if s[k] >= s[max_k]:\n",
    "        max_k = k\n",
    "    if s[k] <= s[min_k]:\n",
    "        min_k = k   \n",
    "\n",
    "print('Centrality for approximation')\n",
    "print(max_k, s[max_k]) # very low centrality overall, max is 0.0021\n",
    "print(min_k, s[min_k]) # min is 0.00020, which is 10 times lowe than the\n",
    "\n",
    "print('Same centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame()\n",
    "df['nodes'] = g.nodes\n",
    "df['Number of neighbors'] = [len(g[i]) for i in df['nodes']]\n",
    "histo_fit = sns.histplot(df['Number of neighbors'])\n",
    "histo_fit.set_title(f'Mean = {mean_deg}, Std = {std_dev}')\n",
    "sns.PairGrid.savefig(histo_fit,'./figures/histo_fit.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>degree</th>\n",
       "      <th>closeness</th>\n",
       "      <th>betweenness</th>\n",
       "      <th>eigenvector</th>\n",
       "      <th>page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   degree  closeness  betweenness  eigenvector  page\n",
       "0     NaN        NaN          NaN          NaN   NaN\n",
       "1     NaN        NaN          NaN          NaN   NaN\n",
       "2     NaN        NaN          NaN          NaN   NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
