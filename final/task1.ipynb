{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task1: Network Identification\n",
    "Consider the network N represented in the file net_x, where x is your group number.\n",
    "This network has been generated with one of the network models seen during the course.\n",
    "You have to analyze the network N with the network mining tools (the ones shortlisted in the\n",
    "midterm project) and guess which model has been used for creating it. Your guess has to be\n",
    "supported by an appropriate set of experiments to confirm that networks generated with the\n",
    "proposed model have characteristics similar to N (note that you have to guess also the parameters of\n",
    "the model).\n",
    "During the discussion of the project, you will be asked to motivate your guess. Motivations may be\n",
    "related to both theoretical properties of the models seen during the course (e.g., “I analyzed the\n",
    "provided network and I observed that its node degree distribution follows a power law. Hence, I\n",
    "conclude that it is not possible that the graph has been generated with a model random(n, p).”), and\n",
    "to experimental evidence (e.g., “I generated a lot of random graphs with p = 1/3, and none of them\n",
    "had similar properties as the provided network. Hence I conclude that it is improbable that the graph\n",
    "is random(n, 1/3)”).\n",
    "A bonus point will be assigned to all the components of the groups whose guess is closer to the\n",
    "model (and parameters) used to generate N.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 1:\n",
    "import networkx as nx\n",
    "from joblib import Parallel, delayed, cpu_count\n",
    "import pandas as pd\n",
    "import itertools as it\n",
    "import math\n",
    "from scipy.sparse import linalg\n",
    "import random\n",
    "from sklearn.cluster import SpectralClustering\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of graphs it can be:\n",
    "configurationG(deg)\n",
    "power_law_degree(n,power)\n",
    "preferentialG(n,p)\n",
    "GenWS2DG(n, r, k, q)\n",
    "affiliationG(n, m, q, c, p, s)\n",
    "randomG(n,p)\n",
    "\n",
    "\n",
    "info:\n",
    "Is undirected\n",
    "follows a normal distribution of neighbors with mean 23.3\n",
    "\n",
    "Parameters:\n",
    "Nodes: 20000\n",
    "edges: 227739\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n",
      "227739\n",
      "True\n",
      "23.24426676942118\n",
      "1424 0.0021001050052502626\n",
      "10443 0.000200010000500025\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "with open('net_3', 'r') as f:\n",
    "    for s in f.readlines():\n",
    "        G.add_edge(s.split()[0], s.split()[1])\n",
    "\n",
    "print(G.number_of_nodes())\n",
    "print(G.number_of_edges())\n",
    "\n",
    "# graph is connected\n",
    "print(nx.is_connected(G))\n",
    "\n",
    "# Average degree of neighbors in the graph, tells us that on average a neihgbor of a node has 23.24 connections\n",
    "# which is a very connected graph\n",
    "mean_deg = print(np.mean(list(nx.average_neighbor_degree(G).values())))\n",
    "\n",
    "#print(nx.node_connectivity(g))\n",
    "\n",
    "s = nx.degree_alg.degree_centrality(G)\n",
    "max_k = '0'\n",
    "min_k = '0'\n",
    "for k in s:\n",
    "    if s[k] >= s[max_k]:\n",
    "        max_k = k\n",
    "    if s[k] <= s[min_k]:\n",
    "        min_k = k   \n",
    "print(max_k, s[max_k]) # very low centrality overall, max is 0.0021\n",
    "print(min_k, s[min_k]) # min is 0.00020, which is 10 times lowe than the max\n",
    "\n",
    "#print(nx.diameter(g)) # Should take some time to compute. Value is:\n",
    "a = []\n",
    "for i in G.nodes:\n",
    "    a.append(len(G[i]))\n",
    "\n",
    "std_deg = np.std(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the different kinds of centralities\n",
    "import networkx as nx\n",
    "def centrality(G):\n",
    "    # degree centrality\n",
    "    d_cen = nx.degree_centrality(G) # takes 5 seconds\n",
    "    print('degree done')\n",
    "    # closeness centrality\n",
    "    c_cen = nx.closeness_centrality(G) # takes 12 minutes\n",
    "    print('closeness done')\n",
    "    # betweenness centrality\n",
    "    #b_cen = nx.betweenness_centrality(G) # takes forever 50\n",
    "    #print('betweenness done')\n",
    "    # eulerian centrality\n",
    "    #e_cen = nx.eigenvector_centrality(G)\n",
    "    #print('eulerian done')\n",
    "    # return the different centralities\n",
    "    # return [[min(d_cen),max(d_cen)], [min(c_cen),max(c_cen)], [min(b_cen),max(b_cen)]]\n",
    "    return [d_cen, c_cen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[0;32m      2\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnodes\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m G\u001B[38;5;241m.\u001B[39mnodes\n\u001B[1;32m----> 3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber of neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mlen\u001B[39m(G[i]) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnodes\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#df['centrality'] = [nx.centrality.closeness.closeness_centrality(g,i) for i in df['nodes']]\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39mstd(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber of neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "Cell \u001B[1;32mIn[15], line 3\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m      1\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[0;32m      2\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnodes\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m G\u001B[38;5;241m.\u001B[39mnodes\n\u001B[1;32m----> 3\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber of neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mlen\u001B[39m(\u001B[43mG\u001B[49m\u001B[43m[\u001B[49m\u001B[43mi\u001B[49m\u001B[43m]\u001B[49m) \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnodes\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m#df['centrality'] = [nx.centrality.closeness.closeness_centrality(g,i) for i in df['nodes']]\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(np\u001B[38;5;241m.\u001B[39mstd(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumber of neighbors\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\networkx\\classes\\graph.py:513\u001B[0m, in \u001B[0;36mGraph.__getitem__\u001B[1;34m(self, n)\u001B[0m\n\u001B[0;32m    489\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, n):\n\u001B[0;32m    490\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Returns a dict of neighbors of node n.  Use: 'G[n]'.\u001B[39;00m\n\u001B[0;32m    491\u001B[0m \n\u001B[0;32m    492\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    511\u001B[0m \u001B[38;5;124;03m    AtlasView({1: {}})\u001B[39;00m\n\u001B[0;32m    512\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 513\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43madj\u001B[49m\u001B[43m[\u001B[49m\u001B[43mn\u001B[49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\networkx\\classes\\coreviews.py:81\u001B[0m, in \u001B[0;36mAdjacencyView.__getitem__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m     80\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name):\n\u001B[1;32m---> 81\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m AtlasView(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_atlas\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m)\n",
      "\u001B[1;31mTypeError\u001B[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['nodes'] = G.nodes\n",
    "df['number of neighbors'] = [len(G[i]) for i in df['nodes']]\n",
    "#df['centrality'] = [nx.centrality.closeness.closeness_centrality(g,i) for i in df['nodes']]\n",
    "print(np.std(df['number of neighbors']))\n",
    "print(np.mean(df['number of neighbors']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG = centrality(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'number of neighbors'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3652\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3651\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'number of neighbors'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[11], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m hist_facit \u001B[38;5;241m=\u001B[39m sns\u001B[38;5;241m.\u001B[39mhistplot(\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnumber of neighbors\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      4\u001B[0m sns\u001B[38;5;241m.\u001B[39mPairGrid\u001B[38;5;241m.\u001B[39msavefig(hist_facit,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./figures/histo_facit.png\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32mc:\\users\\lenovo\\venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3654\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3653\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3654\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3655\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3656\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'number of neighbors'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "hist_facit = sns.histplot(df['number of neighbors'])\n",
    "sns.PairGrid.savefig(hist_facit,'./figures/histo_facit.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = nx.degree_alg.degree_centrality(G)\n",
    "max_k = '0'\n",
    "min_k = '0'\n",
    "for k in s:\n",
    "    if s[k] >= s[max_k]:\n",
    "        max_k = k\n",
    "    if s[k] <= s[min_k]:\n",
    "        min_k = k   \n",
    "print('Centrality for net_3')\n",
    "print(max_k, s[max_k]) # very low centrality overall, max is 0.0021\n",
    "print(min_k, s[min_k]) # min is 0.00020, which is 10 times lowe than the\n",
    "s = nx.degree_alg.degree_centrality(G)\n",
    "max_k = 0\n",
    "min_k = 0\n",
    "for k in s:\n",
    "\n",
    "    if s[k] >= s[max_k]:\n",
    "        max_k = k\n",
    "    if s[k] <= s[min_k]:\n",
    "        min_k = k   \n",
    "\n",
    "print('Centrality for approximation')\n",
    "print(max_k, s[max_k]) # very low centrality overall, max is 0.0021\n",
    "print(min_k, s[min_k]) # min is 0.00020, which is 10 times lowe than the\n",
    "\n",
    "print('Same centrality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "df = pd.DataFrame()\n",
    "df['nodes'] = G.nodes\n",
    "df['Number of neighbors'] = [len(G[i]) for i in df['nodes']]\n",
    "std_dev = np.std(df['Number of neighbors'])\n",
    "mean_deg = np.mean(df['Number of neighbors'])\n",
    "num_nodes = 20000\n",
    "data = []\n",
    "for i in range(10):\n",
    "    data.append(np.round(np.random.normal(mean_deg, std_dev, num_nodes)).astype(int))\n",
    "sorted_data = [sorted(sublist) for sublist in data]\n",
    "\n",
    "# Create a new list based on the average of each index\n",
    "degrees = [int(sum(column) / len(column)) for column in zip(*sorted_data)]\n",
    "\n",
    "if sum(degrees) % 2 != 0:\n",
    "    degrees[0]-=1\n",
    "\n",
    "g = nx.configuration_model(degrees)\n",
    "df_ex = pd.DataFrame()\n",
    "df_ex['nodes'] = g.nodes\n",
    "df_ex['Number of neighbors'] = [len(g[i]) for i in df_ex['nodes']]\n",
    "histo_fit = sns.histplot(df_ex['Number of neighbors'])\n",
    "histo_fit.set_title(f'Mean = {mean_deg}, Std = {std_dev}')\n",
    "sns.PairGrid.savefig(histo_fit,'./figures/histo_fit.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create the first graph\n",
    "G1 =  G\n",
    "\n",
    "G2 = g\n",
    "\n",
    "# Graph isomorphism\n",
    "is_isomorphic = nx.is_isomorphic(G1, G2)\n",
    "print(\"Isomorphic: \", is_isomorphic)\n",
    "\n",
    "# Node Matching - Jaccard similarity\n",
    "# node_similarity = nx.jaccard_coefficient(G1, G2.edges())\n",
    "# for u, v, sim in node_similarity:\n",
    "#     print(\"Jaccard similarity between nodes\", u, \"and\", v, \":\", sim)\n",
    "\n",
    "# # Edge Matching - Jaccard index\n",
    "# edge_similarity = nx.jaccard_coefficient(G1.edges(), G2.edges())\n",
    "# for u, v, sim in edge_similarity:\n",
    "#     print(\"Jaccard similarity between edges\", u, \"and\", v, \":\", sim)\n",
    "\n",
    "\n",
    "# Community Structure Comparison - Normalized Mutual Information\n",
    "communities_G1 = nx.algorithms.community.greedy_modularity_communities(G1)\n",
    "communities_G2 = nx.algorithms.community.greedy_modularity_communities(G2)\n",
    "normalized_mutual_info = nx.algorithms.community.quality.normalized_mutual_information(communities_G1, communities_G2)\n",
    "print(\"Normalized Mutual Information:\", normalized_mutual_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfG_cen = sorted(list(nx.degree_centrality(G).values()))\n",
    "dfg_cen = sorted(list(nx.degree_centrality(g).values()))\n",
    "\n",
    "threshold = 10**-5\n",
    "k = 0\n",
    "for i in range(len(dfG_cen)):\n",
    "    if abs(dfG_cen[i] - dfg_cen[i]) > threshold:\n",
    "        k += 1\n",
    "print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "size = 20000\n",
    "# Generating data for power law distribution\n",
    "power_data = np.random.power(3, size=size) * 40  # Scale data to the range of 0-40\n",
    "\n",
    "inv_power_data = np.random.power(1/3, size=size) * 40  # Scale data to the range of 0-40\n",
    "\n",
    "# Generating data for normal distribution\n",
    "normal_data = np.random.normal(loc=20, scale=5, size=size)  # Adjust mean and standard deviation as desired\n",
    "\n",
    "# Generating data for random distribution\n",
    "random_data = np.random.random(size=size) * 40  # Scale data to the range of 0-10\n",
    "\n",
    "# Plotting power law distribution\n",
    "sns.kdeplot(power_data, color='red', label='Power Law = 3')\n",
    "\n",
    "# Plotting inv power law distribution\n",
    "sns.kdeplot(inv_power_data, color='orange', label='Power Law = 1/3')\n",
    "\n",
    "# Plotting normal distribution\n",
    "sns.kdeplot(normal_data, color='green', label='Normal Distribution')\n",
    "\n",
    "# Plotting random distribution\n",
    "sns.kdeplot(random_data, color='blue', label='Random Distribution')\n",
    "\n",
    "# Setting plot labels and title\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Power Law vs. Normal vs. Random Distribution')\n",
    "\n",
    "# Setting x-axis limits\n",
    "plt.xlim(0, 40)\n",
    "\n",
    "# Adding legend\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure as a PNG file\n",
    "plt.savefig('figures/distribution_plot.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}